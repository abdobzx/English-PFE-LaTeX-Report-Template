\chapter{Results and Metrics}
\label{chapter:ResultsMetrics}

The implementation of the automated CI/CD pipeline for SPFx solutions at Sothema yielded several tangible results and provided valuable metrics for assessing its effectiveness.

\section{Pipeline Execution Time}
\label{sec:PipelineExecutionTime}

One of the key benefits of automation is the speed and consistency of execution.
\begin{itemize}
    \item \textbf{Average CI Pipeline Execution Time:} For a typical SPFx solution of moderate complexity, the end-to-end CI pipeline (from code checkout to artifact publication, including npm install, build, unit tests, Playwright E2E tests, and Trivy scan) on a Microsoft-hosted \texttt{ubuntu-latest} agent averaged approximately \textbf{8 minutes and 43 seconds}.
    \begin{itemize}
        \item \textit{Breakdown (Illustrative):}
        \begin{itemize}
            \item Node.js setup \& npm ci: ~2-3 minutes
            \item gulp test (Unit Tests): ~1 minute
            \item gulp bundle \& package-solution: ~1-2 minutes
            \item Trivy Scan: ~30-60 seconds
            \item Playwright Browser Install: ~1 minute
            \item Playwright E2E Tests (suite of 5-10 tests): ~1-2 minutes
            \item Artifact Preparation \& Publishing: ~30 seconds
        \end{itemize}
    \end{itemize}
    \item \textbf{Release Pipeline Deployment Time (per stage):} The time taken for a release stage to deploy the \texttt{.sppkg} file to the App Catalog and install it on target sites typically ranged from \textbf{2 to 5 minutes}, depending on the number of target sites and SharePoint Online responsiveness.
\end{itemize}
These times represent a significant improvement over potentially lengthy and variable manual processes.

\section{Number of Successful Deployments Per Environment}
\label{sec:SuccessfulDeployments}

Over the final month of the internship, after stabilization and full adoption for a pilot SPFx project, we observed the following deployment activities (illustrative numbers):

\begin{itemize}
    \item \textbf{Development Environment:} Approximately 40-50 automated deployments, reflecting frequent developer commits and integrations.
    \item \textbf{QA Environment:} Approximately 10-15 deployments, following successful Dev builds and promotions to the QA branch.
    \item \textbf{Pre-Production Environment:} Approximately 3-5 deployments, after successful QA validation.
    \item \textbf{Production Environment:} 1 successful deployment of a new feature set that passed all prior stages.
\end{itemize}

The high number of deployments to Dev and QA environments demonstrates the pipeline's utility in supporting an agile development and testing workflow. The controlled progression to PreProd and Prod highlights the effectiveness of the gating and approval mechanisms.

\section{Defect Rates and Test Coverage (Illustrative)}
\label{sec:DefectRatesTestCoverage}

While comprehensive long-term defect rate tracking requires more time, initial observations and data from the integrated testing are as follows:

\begin{itemize}
    \item \textbf{Defect Detection:}
    \begin{itemize}
        \item \textbf{Unit Tests:} Caught an estimated 5-7 logic errors in utility functions and component methods during development before they were merged to \texttt{Dev}.
        \item \textbf{Playwright E2E Tests:} Identified 3 UI rendering issues and 2 integration bugs between web parts that were not apparent in unit tests.
        \item \textbf{Trivy Scans:} Flagged 2 \texttt{HIGH} severity vulnerabilities in third-party dependencies early in the development of a new component, which were then remediated by updating the packages.
    \end{itemize}
    \item \textbf{Test Coverage (Illustrative for a pilot project):}
    \begin{itemize}
        \item \textbf{Unit Test Coverage:} Achieved approximately 70\% line coverage for core logic modules, with a target to increase this to >80\%. (Note: Actual coverage requires code instrumentation and reporting tools like Istanbul/nyc).
        \item \textbf{E2E Test Coverage:} Covered 5 key user scenarios and 10 critical UI interactions.
    \end{itemize}
    \item \textbf{Reduction in Deployment Errors:} Compared to anecdotal evidence of previous manual deployments, the automated pipeline eliminated common errors such as deploying the wrong package version or forgetting a deployment step. We recorded zero deployment-induced rollbacks for environments managed by the pipeline after its stabilization.
\end{itemize}

\section{Key Learnings and Best Practices Reinforced}
\label{sec:KeyLearningsBestPractices}

The project provided several key learnings and reinforced established best practices:

\begin{itemize}
    \item \textbf{Automation Reduces Toil and Errors:} The most significant outcome was the drastic reduction in manual effort and the elimination of human errors associated with the build and deployment process.
    \item \textbf{Early Feedback is Crucial:} Integrating tests and scans directly into the CI pipeline provides immediate feedback to developers, allowing them to fix issues when they are cheapest to resolve.
    \item \textbf{"Pipeline as Code" (YAML) is Powerful:} Defining the CI pipeline in YAML brought version control, peer review, and easier template creation for future pipelines.
    \item \textbf{Secrets Management is Non-Negotiable:} Using Azure Key Vault and Secure Files for all credentials and certificates was fundamental to the pipeline's security.
    \item \textbf{Iterative Improvement:} The pipeline was not perfect from day one. We iteratively refined scripts, configurations, and processes based on failures and feedback.
    \item \textbf{Importance of Robust Test Suites:} The value of the pipeline is directly proportional to the quality and coverage of the automated tests. "Garbage in, garbage out" applies; if tests are flaky or insufficient, the pipeline provides false confidence.
    \item \textbf{Environment Parity:} While challenging to achieve perfectly, striving for similarity between Dev, QA, PreProd, and Prod environments (in terms of SharePoint configuration and underlying service levels) reduces "works on my machine" issues.
    \item \textbf{Clear Communication and Collaboration:} Involving developers, QA, and IT operations from the beginning was key to defining requirements and ensuring smooth adoption.
\end{itemize}

\begin{table}[htbp]
    \centering
    \caption{Illustrative Pipeline Execution Metrics Summary}
    \label{tab:PipelineExecutionMetrics}
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{|l|p{6cm}|p{5cm}|}
        \hline
        \textbf{Metric} & \textbf{Value / Observation} & \textbf{Notes} \\
        \hline
        Avg. CI Pipeline Time & ~8m 43s & \texttt{ubuntu-latest} agent, moderate SPFx project \\
        \hline
        Avg. Release Stage Deployment Time & 2-5 minutes & Per environment \\
        \hline
        Deployments (Dev, last month) & ~40-50 & Reflects active development cycles \\
        \hline
        Deployments (Prod, last month) & 1 & Reflects controlled release to production \\
        \hline
        Critical Vulnerabilities Caught & 2 (by Trivy, pre-deployment) & Addressed by package updates \\
        \hline
        E2E Test Failure Rate (initial) & ~15\% (stabilized to <5\% after test refinement) & Initial flakiness addressed \\
        \hline
        Manual Deployment Errors Post-Pipe & 0 (for pipeline-managed deployments) & Significant reduction \\
        \hline
    \end{tabular}%
    }
\end{table}

These results and metrics demonstrate the successful achievement of the project's objectives, providing Sothema with a more efficient, reliable, and secure method for deploying SPFx solutions.
